{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPMZRf4DrRwjGSJkzmq2aI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnockCity/KCB_Data_Science_and_AI/blob/master/ModelPerformance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Accuracy** is how well a model can accurately predict values.\n",
        "**Residual(Errors)** is the difference between observed(actual) value and predicted value for a data point."
      ],
      "metadata": {
        "id": "lLT1sfYAkell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Residuals**\n",
        "*Help us understand our well our model is fitting the data\n",
        "*By analysing residuals,we are able to identify the patterns and trends our model is not capturing.\n",
        "**When to use them:**\n",
        "*Are useful in understanding pattern of errors the model is making and diagnosing issues with our model.\n",
        "*Used to identify outliers or influential  data points.\n",
        "\n",
        "** smaller residuals indicate a more accurate model and vice versa\n",
        "\n",
        "**Residual plots**\n",
        "*are scatter plots of the residual values and determine the accuracy of the model.\n",
        "*Residuals are randomly scattered around zero with no discernble pattern.\n",
        "*Clear patterns or trends in residual plots suggests bais or shortcomings in the model."
      ],
      "metadata": {
        "id": "lHFSan8XlURE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model accuracy and Metrics**\n",
        "*For reliable prediction\n",
        "*Resource optimization\n",
        "*Risk management\n",
        "*Improved understanding\n",
        "*Enhanced competitiveness\n",
        "*Trust and credibility\n"
      ],
      "metadata": {
        "id": "h4E_2dFeoCAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common measures of accuracy are:\n",
        "**They quantify the residuals(errors) of a model's predictions and provide a way to compare the accuracy of different models.\n",
        "\n",
        "**Mean Absolute Error(MAE)**-reps. average distance between observed and predicted vales.\n",
        "*Shows how far the predictions are on average fron true values.\n",
        "*Low MAE values indicate more accurate model\n",
        "*Easy to interpret and less sensitive to outliers,hence a good measure of average prediction error.\n",
        "*Does not punish large errors(drawback)when large errors considered are critcal.\n",
        "\n",
        "**Mean Squared Error(MSE)**-average of squared residuals.Emphasizes large errors by squaring them,making it more sensitive to outliers.\n",
        "*Low MSE values indicates more accurate model.\n",
        "*Penalize larger errors more heavily than smaller errors as errors are squared,therefore large errors have a greater impact on the overall value.\n",
        "*Sensitive to outliers(drawback)\n",
        "\n",
        "**Root Mean Squared Error(RMSE)**-square root of MSE.Reps.average distance between observed and predicted vales,similar to MAE,but with more emphasis on large errors.\n",
        "*Is more interpretable than MSE as it is in the same unit as the original data.\n",
        "For instance, a RMSE of 2, means that on average,the models prediction's are off by 2 units,in the same units as the target variable.\n",
        "*Sensitive to outliers(drawback)\n",
        "\n",
        "**Interpretting the accuracy in the context**\n",
        "*It is crucial to interpret our model in the context we are investigating.\n"
      ],
      "metadata": {
        "id": "3SC921TVoJzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When evaluating model accuracy,two importaznt components to consider are:**\n",
        "(i)**Bias**\n",
        "-is the error introduced by model's assumptions or simplifications,causing it consistently miss the mark when making predictions.\n",
        "-how close the predictions are to the actual values.(low/high bias)\n",
        "-A model with high bias oversimplifies the underlying relationships in the data and fails to capture the true patterns leading to poor performance.\n",
        "\n",
        "(ii)**Variance**\n",
        "-is the model's sensitivity to fluctuations in the training data.\n",
        "-it measures how much the predictions of the model vary when fitted on different subsets of data.\n",
        "-how spread the errors are,if no pattern or cluster ,indicates high variance.\n",
        "-a model with high variance tends to overfit the training data,i.e it memorises the training data instead of learning the learning patterns causing poor performance when tested on new data.\n",
        "\n",
        "**Causes of Bias and Variance**\n",
        "\n",
        "**(a)Causes of Bias**\n",
        "(i)Model simplicity\n",
        "-a model that lacks complexity to capture the underlying patterns in the data can result in high bias.\n",
        "(ii)Under-representative features\n",
        "-if critical features/variables are not included in the model,it may overlook critical information leading to inaccurate predictions.\n",
        "(iii)Incorrect assumptions\n",
        "-Buliding a model on incorrect assumptions about the data or relationship can introduce bias.\n",
        "\n",
        "**(b)Causes of Variance**\n",
        "(i)Model complexity\n",
        "-complex models with excessive parameters can result to high variance leading to poor generalisation or unseen data.\n",
        "(ii)Over-reliance on noise\n",
        "-fitting the noise instead of true patterns leads to poor performance on unseen data.\n",
        "(iii)Insufficient training data\n",
        "-the model struggles to learn the true underlying patterns effectively.\n",
        "\n",
        "**Reducing bias and variance.**\n",
        "**(a)Reducing bias**\n",
        "*use more complex models that can capture intricate patterns\n",
        "*Incorporate additional relevant features or variables in the model.\n",
        "*Increase model's flexibility or capacity such as by using different types of models.\n",
        "**(b)Reducing Variance**\n",
        "*Increase the amount of training data to provide the model with more diverse examples.\n",
        "*Use a dimensional reduction technique which reduces the number of features in a dataset while preserving the most relevant information.\n",
        "*Simplify the model by reducing its complexity,such as decreasing the number of features or feature selection techniques.\n",
        "\n",
        "**Other challenges to model accuracy**\n",
        "(i)Heteroskedasticity\n",
        "-is a situation in which variation of errors in a statistical models is not constant across range of independent variables.I.e spread or dispersion of errors is not consistent.\n",
        "-this can have implications for the accuracy and reliability of model's prediction.\n",
        "-can be detected through visual inspection of residual plot\n",
        "-if the resulting graph has a fan or cone shape,it suggests presence of heteroskedasticity.\n",
        "\n",
        "**solutions to heteroskedasticity**.\n",
        "-We aim for homoscedasticity.\n",
        "*Transforming the data-taking logarithm,square root or reciprocal of variables.\n",
        "*Weighted least square regression-observation with higher variance are given less weight while those with small variance are given more weight.This gives more importance to observation with less variability,mitigating heteroskedasticity.\n",
        "*Robust standard errors\n",
        "-Standard errors help us understand how much estimated values of sample data might vary when sampling process is repeated multiple times.\n",
        "-provide valid statistical inference even when heteroskedasticity is present.\n",
        "\n",
        "(ii)Autocorrelation(Endogeneity)\n",
        "-is a situation in which there is a two-way relationship between a variable of interest and other variables in a statistcal model(correlation)\n",
        "-this implies the variable you are trying to study is influenced by other factors, and at the same,it also influences those factors.\n",
        "-this intertwined relationship makes it challenging to disentangle which factor which truly leads to changes in the variable under study.\n",
        "\n",
        "**solutions to endogeneity**\n",
        "*Instrumental variable(IV) analysis - is a variable that is correlated with endogeneity but not directly related to the outcome variable.\n",
        "-it acts as a tool to help us estimate the causal effect of endogeneity variable on the outcome variable.\n",
        "*Control variables-including additional control variables helps us account for other factors that may be related to both IV and DV,thus reducing effect of endogeinity.\n",
        "-however,control variables should not be endogenous.\n",
        "*Difference-in-Differences(DID)-this technique compares the changes in outcome variable over time between treatment group and control group.\n",
        "-it accounts for causal effect while accounting for confounding factors."
      ],
      "metadata": {
        "id": "E2Lqu3i-4VPt"
      }
    }
  ]
}